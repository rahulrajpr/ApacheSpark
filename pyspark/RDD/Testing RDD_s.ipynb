{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0e12d3",
   "metadata": {},
   "source": [
    "# Testing RDD functionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed0da35",
   "metadata": {},
   "source": [
    "Resilient Distributed Datasets (RDD) is a fundamental data structure of Spark. It is an immutable distributed collection of objects. Each dataset in RDD is divided into logical partitions, which may be computed on different nodes of the cluster. RDDs can contain any type of Python, Java, or Scala objects, including user-defined classes.\n",
    "\n",
    "https://www.tutorialspoint.com/apache_spark/apache_spark_rdd.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "520d164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8eafb6",
   "metadata": {},
   "source": [
    "### Create Spark Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4235c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/01 19:30:11 WARN Utils: Your hostname, systemd resolves to a loopback address: 127.0.1.1; using 192.168.0.141 instead (on interface wlp3s0)\n",
      "23/07/01 19:30:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/systemd/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/01 19:30:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Import spark session from pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# create a spark application\n",
    "\n",
    "spark = SparkSession.builder.appName('TestingRDDs').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd864808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'awesome', 'practice', 'in', 'spark', 'and', 'Python', 'and', 'I', 'love', 'Spark,', 'Big', 'Data', 'and', 'Python']\n"
     ]
    }
   ],
   "source": [
    "# create a word list\n",
    "\n",
    "word_list = 'This is an awesome practice in spark and Python and I love Spark, Big Data and Python'.split(' ')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95ef10d",
   "metadata": {},
   "source": [
    "### Create the rdd object from above list of the texts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "206d52d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd = spark.sparkContext.parallelize(word_list)\n",
    "\n",
    "type(word_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "227b904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'awesome',\n",
       " 'practice',\n",
       " 'in',\n",
       " 'spark',\n",
       " 'and',\n",
       " 'Python',\n",
       " 'and',\n",
       " 'I',\n",
       " 'love',\n",
       " 'Spark,',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'and',\n",
       " 'Python']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27cc45",
   "metadata": {},
   "source": [
    "### Count the elements in the RDD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75a4164f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8006da",
   "metadata": {},
   "source": [
    "### Access the unique elements in an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20e9ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark',\n",
       " 'I',\n",
       " 'in',\n",
       " 'awesome',\n",
       " 'love',\n",
       " 'an',\n",
       " 'Spark,',\n",
       " 'This',\n",
       " 'Data',\n",
       " 'Python',\n",
       " 'practice',\n",
       " 'and',\n",
       " 'is',\n",
       " 'Big']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_word_rdd = word_rdd.distinct()\n",
    "\n",
    "distinct_word_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12e06dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_word_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447b839",
   "metadata": {},
   "source": [
    "### Filter function in RDD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b0eef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spark']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.filter(lambda x : x.startswith('s')).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209e093",
   "metadata": {},
   "source": [
    "### Map function in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbf34dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'awesome',\n",
       " 'practice',\n",
       " 'in',\n",
       " 'spark',\n",
       " 'and',\n",
       " 'python',\n",
       " 'and',\n",
       " 'i',\n",
       " 'love',\n",
       " 'spark,',\n",
       " 'big',\n",
       " 'data',\n",
       " 'and',\n",
       " 'python']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.map(lambda x : x.lower().strip()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6a3bc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'T', False),\n",
       " ('is', 'i', False),\n",
       " ('an', 'a', False),\n",
       " ('awesome', 'a', False),\n",
       " ('practice', 'p', False),\n",
       " ('in', 'i', False),\n",
       " ('spark', 's', True),\n",
       " ('and', 'a', False),\n",
       " ('Python', 'P', False),\n",
       " ('and', 'a', False),\n",
       " ('I', 'I', False),\n",
       " ('love', 'l', False),\n",
       " ('Spark,', 'S', False),\n",
       " ('Big', 'B', False),\n",
       " ('Data', 'D', False),\n",
       " ('and', 'a', False),\n",
       " ('Python', 'P', False)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.map(lambda x : (x, x[0], x.startswith('s'))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4b3e1",
   "metadata": {},
   "source": [
    "### Map vs FlatMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe839f3",
   "metadata": {},
   "source": [
    "`map` applies a specified function to each element of an RDD and returns a new RDD. The output RDD will have the same number of elements as the input RDD, where each element is the result of applying the function to the corresponding element in the input RDD. The function in map can return multiple elements as a collection, but they will be treated as a single element in the output RDD.\n",
    "\n",
    "On the other hand, `flatMap` is similar to map but allows the function to return multiple elements as separate items in the resulting RDD. It \"flattens\" the returned collections into individual elements. The output RDD from flatMap will have a potentially different number of elements than the input RDD, as each returned collection can contribute multiple elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dcafca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['T', 'h', 'i', 's'],\n",
       " ['i', 's'],\n",
       " ['a', 'n'],\n",
       " ['a', 'w', 'e', 's', 'o', 'm', 'e'],\n",
       " ['p', 'r', 'a', 'c', 't', 'i', 'c', 'e'],\n",
       " ['i', 'n'],\n",
       " ['s', 'p', 'a', 'r', 'k'],\n",
       " ['a', 'n', 'd'],\n",
       " ['P', 'y', 't', 'h', 'o', 'n'],\n",
       " ['a', 'n', 'd'],\n",
       " ['I'],\n",
       " ['l', 'o', 'v', 'e'],\n",
       " ['S', 'p', 'a', 'r', 'k', ','],\n",
       " ['B', 'i', 'g'],\n",
       " ['D', 'a', 't', 'a'],\n",
       " ['a', 'n', 'd'],\n",
       " ['P', 'y', 't', 'h', 'o', 'n']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.map(lambda word : list(word)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "179f436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 'w',\n",
       " 'e',\n",
       " 's',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " 'p',\n",
       " 'r',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " 'i',\n",
       " 'n',\n",
       " 's',\n",
       " 'p',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " 'P',\n",
       " 'y',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 'n',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " 'I',\n",
       " 'l',\n",
       " 'o',\n",
       " 'v',\n",
       " 'e',\n",
       " 'S',\n",
       " 'p',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ',',\n",
       " 'B',\n",
       " 'i',\n",
       " 'g',\n",
       " 'D',\n",
       " 'a',\n",
       " 't',\n",
       " 'a',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " 'P',\n",
       " 'y',\n",
       " 't',\n",
       " 'h',\n",
       " 'o',\n",
       " 'n']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.flatMap(lambda word : list(word)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5effc7bb",
   "metadata": {},
   "source": [
    "### Sort by Key in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9b39f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = [('USA',100),('India',50),('Japan',70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "055afd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_rdd = spark.sparkContext.parallelize(country_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fea4dad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USA', 100), ('India', 50), ('Japan', 70)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84642cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', 50), ('Japan', 70), ('USA', 100)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_rdd.sortByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7d72c",
   "metadata": {},
   "source": [
    "Now you can see the rdd consider the first elecmennt of the rdd object as the key.\n",
    "if we need to the sord based on the other element lets apply map to put that element first and do the sorting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8778c234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, 'India'), (70, 'Japan'), (100, 'USA')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_rdd.map(lambda c : (c[1],c[0])).sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6378f609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, 'USA'), (70, 'Japan'), (50, 'India')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_rdd.map(lambda c : (c[1],c[0])).sortByKey(ascending = False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc6bf5",
   "metadata": {},
   "source": [
    "### RDD Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c556fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [1,2,4,5,10,19,101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1baaaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rdd = spark.sparkContext.parallelize(num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7df054eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51172943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d15ec863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0968e020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.285714285714285"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7aa502a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c5a6570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.43955863393913"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rdd.stdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c9b77c",
   "metadata": {},
   "source": [
    "### RDD Reduce Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "084cf15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the sum of the values in the rdd using the reduce function\n",
    "\n",
    "num_rdd.reduce(lambda x,y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b64d4901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reduce to the max in the values\n",
    "\n",
    "num_rdd.reduce(lambda x,y : x if x > y else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ecb8532b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'practice'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to reduce to the word has maximum number of the letters in it\n",
    "\n",
    "word_rdd.reduce(lambda x,y : x if len(x) > len(y) else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa496b",
   "metadata": {},
   "source": [
    "Lets check the results by the following action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02526635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 'practice'),\n",
       " (7, 'awesome'),\n",
       " (6, 'Python'),\n",
       " (6, 'Spark,'),\n",
       " (6, 'Python'),\n",
       " (5, 'spark'),\n",
       " (4, 'This'),\n",
       " (4, 'love'),\n",
       " (4, 'Data'),\n",
       " (3, 'and'),\n",
       " (3, 'and'),\n",
       " (3, 'Big'),\n",
       " (3, 'and'),\n",
       " (2, 'is'),\n",
       " (2, 'an'),\n",
       " (2, 'in'),\n",
       " (1, 'I')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.map(lambda x : (len(x),x)).sortByKey(ascending = False).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342b4c0",
   "metadata": {},
   "source": [
    "Thats the end of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
