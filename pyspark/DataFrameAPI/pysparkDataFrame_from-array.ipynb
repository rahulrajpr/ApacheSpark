{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3483909d-07ac-4a5f-8661-4b34adccdd46",
   "metadata": {},
   "source": [
    "### Import the Required classes of the spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec4fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1018429-e2bd-498a-a286-1e21cacc3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField\n",
    "from pyspark.sql.types import StringType,IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff71c120-9155-4715-8406-311bea10d610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets have the dataset as the list of tuples\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3f977f-fa48-4556-ad94-418037195110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/02 15:54:27 WARN Utils: Your hostname, systemd resolves to a loopback address: 127.0.1.1; using 192.168.0.141 instead (on interface wlp3s0)\n",
      "23/07/02 15:54:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/02 15:54:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# instantiating the spark session\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkDataFramePractice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcdaffd0-6df3-4b35-a82e-ed82ba55302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definng the sheme for the dataset using the StructType and StructField\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('firstName', StringType(), True),\n",
    "    StructField('middleName', StringType(), True),\n",
    "    StructField('lastName', StringType(), True),\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('gender', StringType(), True),\n",
    "    StructField('salary', IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c413c694-9ce5-4aba-946d-f4c25f8965c9",
   "metadata": {},
   "source": [
    "### Creating DataFrames from an array of Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad85968-94f0-4a32-b91b-b6e10f122063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets create the dataframe \n",
    "\n",
    "dataframe = spark.createDataFrame(data = data, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad31a839-c3f1-481c-b057-e8920c7d5f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[firstName: string, middleName: string, lastName: string, id: string, gender: string, salary: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeadc529-127f-4bdb-835a-06a00a906da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firstName', 'middleName', 'lastName', 'id', 'gender', 'salary']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6a0777-3b5b-465d-8f92-efa7ea0eee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- middleName: string (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c5fe854-8c19-4dfb-b487-567c56aa1d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstName|middleName|lastName|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 58708)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/site-packages/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/site-packages/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "       ^^^^^^\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/systemd/anaconda3/envs/sparkdf/lib/python3.11/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataframe.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a92af4",
   "metadata": {},
   "source": [
    "The end of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
